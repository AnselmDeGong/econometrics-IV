import streamlit as st
import plotly.graph_objects as go
import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

# å¤šè¯­è¨€æ–‡æœ¬å­—å…¸
lang_dict = {
    'zh': {
        'title': 'IV ç†è®ºæ¨¡æ‹Ÿå™¨ï¼šçº¯ç†è®º IV æ¨¡å‹',
        'exclusion_condition': 'æ’ä»–æ€§æ¡ä»¶: å‡è®¾å·¥å…·å˜é‡ Z ä»…é€šè¿‡å†…ç”Ÿå˜é‡ X å½±å“è¢«è§£é‡Šå˜é‡ Yï¼Œä¸å­˜åœ¨ç›´æ¥å½±å“ã€‚',
        'original_model': 'åŸå§‹æ¨¡å‹',
        'first_stage': 'ç¬¬ä¸€é˜¶æ®µ',
        'second_stage': 'ç¬¬äºŒé˜¶æ®µ',
        'mu1_unbiased': '$\\mu_1$ æ˜¯æ— åä¼°è®¡',
        'param_control': 'æ¨¡å‹å‚æ•°æ§åˆ¶',
        'gamma_label': 'Î³ (IV å¼ºåº¦)',
        'gamma_help': 'æ§åˆ¶å·¥å…·å˜é‡ Z å¯¹ X çš„å½±å“å¼ºåº¦',
        'delta_label': 'Î´ (è¯¯å·®ä¼ å¯¼)',
        'delta_help': 'æ§åˆ¶è¯¯å·®é¡¹ U å¯¹ X çš„å½±å“',
        'phi_label': 'Ï† (æ’ä»–æ€§è¿å)',
        'phi_help': 'æ§åˆ¶ Z å¯¹ Y çš„ç›´æ¥å½±å“',
        'exclusion_violation': 'æ’ä»–æ€§è¿åï¼šÏ† = {:.2f}ï¼ŒZ ç›´æ¥å½±å“ Yï¼ŒIV ä¸€è‡´æ€§å´©å¡Œï¼',
        'weak_iv': 'å¼±å·¥å…·å˜é‡é£é™©ï¼šÎ³ = {:.2f}ï¼ŒIV å¼ºåº¦ä¸è¶³ï¼Œä¼°è®¡é‡æ–¹å·®å°†å¾ˆå¤§ï¼',
        'endogeneity_bias': 'å†…ç”Ÿæ€§åå·®è¾ƒå¤§ï¼šÎ´ = {:.2f}ï¼Œè¯¯å·®é¡¹å¯¹ X å½±å“æ˜¾è‘—ï¼ŒOLS å°†ä¸¥é‡æœ‰åï¼',
        'model_preview': 'ğŸ“‹ ç†è®ºæ¨¡å‹é¢„è§ˆ',
        'param_detail': 'ğŸ“š å‚æ•°è¯¦è§£',
        'variable_def': 'å˜é‡å®šä¹‰',
        'param_meaning': 'å‚æ•°åˆä¹‰',
        'error_term': 'è¯¯å·®é¡¹',
        'instrument': 'å·¥å…·å˜é‡',
        'endogenous': 'å†…ç”Ÿå˜é‡',
        'explained': 'è¢«è§£é‡Šå˜é‡',
        'iv_strength': 'å·¥å…·å˜é‡å¼ºåº¦',
        'error_transmission': 'è¯¯å·®ä¼ å¯¼ç³»æ•°',
        'exclusion_violation_degree': 'æ’ä»–æ€§è¿åç¨‹åº¦',
        'true_effect': 'çœŸå®å› æœæ•ˆåº”',
        'regression_comparison': 'ğŸ“Š å®æ—¶å›å½’ç»“æœå¯¹æ¯”',
        'ols_regression': 'OLS å›å½’',
        'tsls_regression': '2SLS å›å½’',
        'true_value': 'çœŸå®å€¼',
        'model': 'æ¨¡å‹',
        'iv_diagnosis': 'ğŸ” å·¥å…·å˜é‡è¯Šæ–­',
        'first_stage_f': 'ç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡',
        'iv_weak': 'IV è¾ƒå¼± (F < 10)',
        'iv_strong': 'IV å¼ºåº¦è¶³å¤Ÿ',
        'correlation': 'Corr(X, Z)',
        'covariance': 'Cov(X, Z)',
        'visualization': 'ğŸ“ˆ æ•°æ®å¯è§†åŒ–',
        'scatter_plot': 'X vs Y æ•£ç‚¹å›¾ä¸å›å½’çº¿',
        'data_point': 'æ•°æ®ç‚¹',
        'insight': 'ğŸ’¡ å…³é”®æ´å¯Ÿ',
        'ols_bias': 'OLS åå·®',
        'tsls_bias': '2SLS åå·®',
        'improvement': 'æ”¹å–„ç¨‹åº¦',
        'explanation': 'è§£é‡Š',
        # æ–°å¢ï¼šå¼‚è´¨æ€§å¤„ç†æ•ˆåº”ç›¸å…³æ–‡æœ¬
        'hte_section': 'ğŸ¯ å¼‚è´¨æ€§å¤„ç†æ•ˆåº”ä¸å››ç±»ä¸ªä½“',
        'scenario_choice': 'é€‰æ‹©å®éªŒåœºæ™¯',
            'scenario_basic': 'åŸºç¡€æ¨¡å‹',
            'scenario_one_option': 'åœºæ™¯ä¸€ï¼šæ— è¿æŠ—è€… (Defiers = 0%)',
            'scenario_two_option': 'åœºæ™¯äºŒï¼šå¼•å…¥è¿æŠ—è€… (Defiers = 20%)',
        'scenario_hte': 'å¼‚è´¨æ€§å¤„ç†æ•ˆåº”æ¨¡å‹',
        'compliers_label': 'ä¾ä»è€… (Compliers) æ¯”ä¾‹',
        'always_takers_label': 'å§‹ç»ˆæ¥å—è€… (Always-takers) æ¯”ä¾‹',
        'never_takers_label': 'ä»ä¸æ¥å—è€… (Never-takers) æ¯”ä¾‹',
        'defiers_label': 'è¿æŠ—è€… (Defiers) æ¯”ä¾‹',
        'compliers': 'ä¾ä»è€… (Compliers)',
        'always_takers': 'å§‹ç»ˆæ¥å—è€… (Always-takers)',
        'never_takers': 'ä»ä¸æ¥å—è€… (Never-takers)',
        'defiers': 'è¿æŠ—è€… (Defiers)',
        'treatment_effect_compliers': 'ä¾ä»è€…çœŸå®å¤„ç†æ•ˆåº” (Î²_C)',
        'treatment_effect_always': 'å§‹ç»ˆæ¥å—è€…çœŸå®å¤„ç†æ•ˆåº” (Î²_A)',
        'treatment_effect_never': 'ä»ä¸æ¥å—è€…çœŸå®å¤„ç†æ•ˆåº” (Î²_N)',
        'treatment_effect_defiers': 'è¿æŠ—è€…çœŸå®å¤„ç†æ•ˆåº” (Î²_D)',
        'scenario_one': 'åœºæ™¯ä¸€ï¼šæ— è¿æŠ—è€… (Defiers = 0%)',
        'scenario_one_desc': 'éªŒè¯ LATE (Local Average Treatment Effect) å®šç† - IV ä¼°è®¡åº”å®Œç¾æ¢å¤ Compliers çš„å¤„ç†æ•ˆåº”',
        'scenario_two': 'åœºæ™¯äºŒï¼šå¼•å…¥è¿æŠ—è€… (Defiers = 20%)',
        'scenario_two_desc': 'å±•ç¤ºå•è°ƒæ€§å‡è®¾è¿åçš„åæœ - è¿æŠ—è€…çš„å­˜åœ¨å¦‚ä½•æ‰­æ›² IV ä¼°è®¡é‡',
        'individual_type': 'ä¸ªä½“ç±»å‹',
        'proportion': 'æ¯”ä¾‹',
        'true_effect': 'çœŸå®å¤„ç†æ•ˆåº”',
        'late_theorem': 'ğŸ”¬ LATE å®šç†éªŒè¯',
        'late_explanation': 'LATE (Local Average Treatment Effect) æ‰¿è¯ºåœ¨ä»¥ä¸‹å‡è®¾ä¸‹ï¼Œ2SLS ä¼°è®¡çš„æ˜¯ Compliers çš„å¹³å‡å¤„ç†æ•ˆåº”ï¼š',
        'late_assumption_1': '1. æ’ä»–æ€§ï¼šZ åªé€šè¿‡ D å½±å“ Y',
        'late_assumption_2': '2. ç›¸å…³æ€§ï¼šZ ä¸ D ç›¸å…³',
        'late_assumption_3': '3. å•è°ƒæ€§ï¼šä¸å­˜åœ¨è¿æŠ—è€… (Defiers)',
        'late_result_scenario1': 'åœºæ™¯ä¸€ç»“æœï¼šZâ†’Dâ†’Y çš„å•å‘å› æœé“¾ï¼Œæ—  Defiersï¼Œæ»¡è¶³æ‰€æœ‰ LATE å‡è®¾',
        'late_result_scenario2': 'åœºæ™¯äºŒç»“æœï¼šDefiers çš„å­˜åœ¨è¿åå˜è°ƒæ€§å‡è®¾ï¼Œå¯¼è‡´ IV ä¼°è®¡ä¸å†ç­‰äºä»»ä½•ç»„çš„å•ä¸€å¤„ç†æ•ˆåº”',
        'monotonicity_violation': 'âš ï¸ å•è°ƒæ€§å‡è®¾è¿åï¼šå½“ Z=1 æ—¶éƒ¨åˆ†ä¸ªä½“ä¸æ¥å—å¤„ç†ï¼Œå½“ Z=0 æ—¶åˆæ¥å—å¤„ç†',
        'hte_results': 'å¼‚è´¨æ€§å¤„ç†æ•ˆåº”ç»“æœå¯¹æ¯”',
        'scenario_label': 'å®éªŒåœºæ™¯',
    },
    'en': {
        'title': 'IV Theory Simulator: Pure Theoretical IV Model',
        'exclusion_condition': 'Exclusion restriction: Instrument Z affects dependent variable Y only through endogenous variable X, with no direct effect.',
        'original_model': 'Original model',
        'first_stage': 'First stage',
        'second_stage': 'Second stage',
        'mu1_unbiased': '$\\mu_1$ is unbiased estimator',
        'param_control': 'Model Parameter Control',
        'gamma_label': 'Î³ (IV Strength)',
        'gamma_help': 'Control the effect of instrument Z on X',
        'delta_label': 'Î´ (Error Transmission)',
        'delta_help': 'Control the effect of error term U on X',
        'phi_label': 'Ï† (Exclusion Restriction Violation)',
        'phi_help': 'Control direct effect of Z on Y',
        'exclusion_violation': 'Exclusion Restriction Violated: Ï† = {:.2f}, Z directly affects Y, IV consistency collapsed!',
        'weak_iv': 'Weak Instrument Risk: Î³ = {:.2f}, insufficient IV strength, estimator variance will be large!',
        'endogeneity_bias': 'Large Endogeneity Bias: Î´ = {:.2f}, error term has significant effect on X, OLS will be severely biased!',
        'model_preview': 'ğŸ“‹ Theoretical Model Preview',
        'param_detail': 'ğŸ“š Parameter Details',
        'variable_def': 'Variable Definitions',
        'param_meaning': 'Parameter Meanings',
        'error_term': 'Error term',
        'instrument': 'Instrument variable',
        'endogenous': 'Endogenous variable',
        'explained': 'Dependent variable',
        'iv_strength': 'Instrument strength',
        'error_transmission': 'Error transmission coefficient',
        'exclusion_violation_degree': 'Exclusion violation degree',
        'true_effect': 'True causal effect',
        'regression_comparison': 'ğŸ“Š Real-time Regression Comparison',
        'ols_regression': 'OLS Regression',
        'tsls_regression': '2SLS Regression',
        'true_value': 'True value',
        'model': 'Model',
        'iv_diagnosis': 'ğŸ” Instrument Variable Diagnosis',
        'first_stage_f': 'First-Stage F-Statistic',
        'iv_weak': 'Weak IV (F < 10)',
        'iv_strong': 'IV Strength Sufficient',
        'correlation': 'Corr(X, Z)',
        'covariance': 'Cov(X, Z)',
        'visualization': 'ğŸ“ˆ Data Visualization',
        'scatter_plot': 'Scatter Plot: X vs Y with Regression Lines',
        'data_point': 'Data Points',
        'insight': 'ğŸ’¡ Key Insights',
        'ols_bias': 'OLS Bias',
        'tsls_bias': '2SLS Bias',
        'improvement': 'Improvement',
        'explanation': 'Explanation',
        # New additions: Heterogeneous Treatment Effects related text
        'hte_section': 'ğŸ¯ Heterogeneous Treatment Effects and Four Individual Types',
        'scenario_choice': 'Choose Experiment Scenario',
            'scenario_basic': 'Basic Model',
            'scenario_one_option': 'Scenario One: No Defiers (Defiers = 0%)',
            'scenario_two_option': 'Scenario Two: With Defiers (Defiers = 20%)',
        'scenario_hte': 'Heterogeneous Treatment Effects Model',
        'compliers_label': 'Compliers Proportion',
        'always_takers_label': 'Always-takers Proportion',
        'never_takers_label': 'Never-takers Proportion',
        'defiers_label': 'Defiers Proportion',
        'compliers': 'Compliers',
        'always_takers': 'Always-takers',
        'never_takers': 'Never-takers',
        'defiers': 'Defiers',
        'treatment_effect_compliers': 'Compliers True Treatment Effect (Î²_C)',
        'treatment_effect_always': 'Always-takers True Treatment Effect (Î²_A)',
        'treatment_effect_never': 'Never-takers True Treatment Effect (Î²_N)',
        'treatment_effect_defiers': 'Defiers True Treatment Effect (Î²_D)',
        'scenario_one': 'Scenario One: No Defiers (Defiers = 0%)',
        'scenario_one_desc': 'Verify LATE (Local Average Treatment Effect) Theorem - IV estimate should perfectly recover Compliers effect',
        'scenario_two': 'Scenario Two: With Defiers (Defiers = 20%)',
        'scenario_two_desc': 'Demonstrate consequences of monotonicity violation - how Defiers distort IV estimates',
        'individual_type': 'Individual Type',
        'proportion': 'Proportion',
        'true_effect': 'True Treatment Effect',
        'late_theorem': 'ğŸ”¬ LATE Theorem Verification',
        'late_explanation': 'LATE (Local Average Treatment Effect) guarantees that under the following assumptions, 2SLS estimates the average treatment effect for Compliers:',
        'late_assumption_1': '1. Exclusion: Z affects Y only through D',
        'late_assumption_2': '2. Relevance: Z is correlated with D',
        'late_assumption_3': '3. Monotonicity: No Defiers exist',
        'late_result_scenario1': 'Scenario One Result: Unidirectional causal chain Zâ†’Dâ†’Y, no Defiers, all LATE assumptions satisfied',
        'late_result_scenario2': 'Scenario Two Result: Defiers violate monotonicity, IV estimate no longer equals any single group\'s treatment effect',
        'monotonicity_violation': 'âš ï¸ Monotonicity Assumption Violated: When Z=1 some individuals reject treatment, when Z=0 some still accept',
        'hte_results': 'Heterogeneous Treatment Effects Results Comparison',
        'scenario_label': 'Experiment Scenario',
    }
}

# ä¾§è¾¹æ è¯­è¨€é€‰æ‹©
language = st.sidebar.selectbox('Language / è¯­è¨€', ['ä¸­æ–‡', 'English'], key='language_select')
lang = 'zh' if language == 'ä¸­æ–‡' else 'en'
text = lang_dict[lang]

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title(text['title'])

# åœ¨ä¾§è¾¹æ æ·»åŠ æ»‘å—æ§åˆ¶å‚æ•°
st.sidebar.header(text['param_control'])
gamma = st.sidebar.slider(text['gamma_label'], min_value=0.1, max_value=2.0, value=1.0, step=0.1,
                          help=text['gamma_help'])
delta = st.sidebar.slider(text['delta_label'], min_value=0.0, max_value=2.0, value=0.5, step=0.1,
                         help=text['delta_help'])

phi = st.sidebar.slider(
    text['phi_label'],
    min_value=0.0,
    max_value=2.0,
    value=0.0,
    step=0.1,
    help=text['phi_help']
)

# Add option to choose experiment scenario in sidebar
st.sidebar.markdown("---")
st.sidebar.header(text['hte_section'])
scenario_options = [text['scenario_basic'], text['scenario_one_option'], text['scenario_two_option']]
scenario_choice = st.sidebar.radio(text['scenario_choice'], scenario_options)

# æ ¹æ®é€‰æ‹©çš„åœºæ™¯æ˜¾ç¤ºä¸åŒçš„å‚æ•°
# Show different parameters based on selected scenario
if 'åŸºç¡€æ¨¡å‹' in scenario_choice or 'Basic Model' in scenario_choice:
    use_hte = False
else:
    use_hte = True
    
    # å¼‚è´¨æ€§å¤„ç†æ•ˆåº”å‚æ•°è®¾ç½®
    # HTEs parameter settings  
    st.sidebar.markdown("**å››ç±»ä¸ªä½“æ¯”ä¾‹è®¾ç½® (Individual Type Proportions)**")
    st.sidebar.markdown("*æ³¨ï¼šæ¯”ä¾‹æ€»å’Œå°†è‡ªåŠ¨è°ƒæ•´ä¸º100%*")
    
    # ä½¿ç”¨æ•°å€¼è¾“å…¥çš„æ–¹å¼ï¼Œç¡®ä¿æ€»å’Œä¸º100%
    # Use number input to ensure proportions sum to 100%
    col_prop = st.sidebar.columns([1, 1])
    
    with col_prop[0]:
        prop_compliers_temp = st.number_input(
            'ä¾ä»è€… (Compliers) %', 
            min_value=0.0, max_value=100.0, value=40.0, step=1.0, 
            key='prop_compliers'
        )
        prop_always_temp = st.number_input(
            'å§‹ç»ˆæ¥å—è€… (Always-takers) %', 
            min_value=0.0, max_value=100.0, value=30.0, step=1.0,
            key='prop_always'
        )
    
    with col_prop[1]:
        prop_never_temp = st.number_input(
            'ä»ä¸æ¥å—è€… (Never-takers) %', 
            min_value=0.0, max_value=100.0, value=30.0, step=1.0,
            key='prop_never'
        )
        prop_defiers_temp = st.number_input(
            'è¿æŠ—è€… (Defiers) %', 
            min_value=0.0, max_value=100.0, value=0.0, step=1.0,
            key='prop_defiers'
        )
    
    # è®¡ç®—æ€»å’Œå¹¶è‡ªåŠ¨è°ƒæ•´
    # Calculate sum and auto-adjust
    total = prop_compliers_temp + prop_always_temp + prop_never_temp + prop_defiers_temp
    
    if total > 0:
        # æŒ‰æ¯”ä¾‹ç¼©æ”¾æ‰€æœ‰å€¼ï¼Œä½¿æ€»å’Œä¸º100
        # Scale all values proportionally to sum to 100
        prop_compliers = prop_compliers_temp / total
        prop_always = prop_always_temp / total
        prop_never = prop_never_temp / total
        prop_defiers = prop_defiers_temp / total
    else:
        # å¦‚æœå…¨æ˜¯0ï¼Œä½¿ç”¨é»˜è®¤å€¼
        prop_compliers = 0.4
        prop_always = 0.3
        prop_never = 0.3
        prop_defiers = 0.0
    
    # æ˜¾ç¤ºè°ƒæ•´åçš„æ¯”ä¾‹
    # Display adjusted proportions
    st.sidebar.info(f"""
**è°ƒæ•´åçš„æ¯”ä¾‹ (Adjusted Proportions)**:
- ä¾ä»è€… (Compliers): {prop_compliers:.1%}
- å§‹ç»ˆæ¥å—è€… (Always-takers): {prop_always:.1%}
- ä»ä¸æ¥å—è€… (Never-takers): {prop_never:.1%}
- è¿æŠ—è€… (Defiers): {prop_defiers:.1%}
- **æ€»è®¡**: {prop_compliers + prop_always + prop_never + prop_defiers:.1%}
    """)
    
    # å¦‚æœä¸æ˜¯åœºæ™¯ä¸€ï¼ˆæ— DefierséªŒè¯ï¼‰ï¼Œåˆ™é”å®šDefiersä¸º0æˆ–æ˜¾ç¤ºè­¦å‘Š
    # If not Scenario I, lock Defiers or show warning
    if 'æ— Defiers' in scenario_choice and prop_defiers > 0.01:
        st.sidebar.warning("âš ï¸ åœºæ™¯ä¸€åº”ä½¿ç”¨ 0% Defiers æ¥éªŒè¯ LATE å®šç†")
    elif 'å«Defiers' in scenario_choice and prop_defiers < 0.01:
        st.sidebar.info("â„¹ï¸ åœºæ™¯äºŒå»ºè®®è®¾ç½® Defiers > 0 æ¥è§‚å¯Ÿå…¶å½±å“")
    
    # å¼‚è´¨æ€§å¤„ç†æ•ˆåº”å¤§å°è®¾ç½®
    # HTE magnitude settings - å›ºå®šé¢„è®¾å€¼ï¼Œç”¨æˆ·æ— éœ€ä¿®æ”¹
    st.sidebar.markdown("**å¤„ç†æ•ˆåº”é¢„è®¾å€¼ (Treatment Effect Preset Values)**")
    st.sidebar.info("""
æ ¹æ®æ½œåœ¨ç»“æœæ¡†æ¶ (Potential Outcomes Framework):
- **Compliers (Î²_comp) = 5.0** 
- **Always-takers (Î²_always) = 2.0**
- **Never-takers (Î²_never) = 2.0**
- **Defiers (Î²_defiers) = 2.0**
    """)
    
    # å›ºå®šå¤„ç†æ•ˆåº”å€¼
    # Fixed treatment effect values
    beta_compliers = 5.0
    beta_always = 2.0
    beta_never = 2.0
    beta_defiers = 2.0

# æ¨¡å‹é¢„è§ˆåŒº
st.markdown(f"### {text['model_preview']}")
st.markdown("---")

# æ ¹æ®åœºæ™¯æ˜¾ç¤ºä¸åŒçš„æ¨¡å‹
# Show different models based on scenario
if use_hte:
    st.markdown("#### æ½œåœ¨ç»“æœæ¡†æ¶ä¸­çš„ LATE æ¨¡å‹ä¸å¼‚è´¨æ€§å¤„ç†æ•ˆåº”")
    st.markdown("(LATE Model with Heterogeneous Treatment Effects in Potential Outcomes Framework)")
    
    st.markdown("""
**äºŒå…ƒå·¥å…·å˜é‡æ¨¡å‹ (Binary Instrumental Variable Model)**:

**ç»“æ„å¼ (Structural Form):**
$$Y_i = \\beta_0 + \\beta_1 X_{1i} + \\boldsymbol{\\beta} \\mathbf{X} + \\epsilon_i$$

å…¶ä¸­ï¼š
- $Y_i$ æ˜¯è¢«è§£é‡Šå˜é‡ (dependent variable)
- $X_{1i}$ æ˜¯å†…ç”Ÿå¤„ç†å˜é‡ (endogenous treatment variable)
- $\\mathbf{X}$ æ˜¯å…¶ä»–å¤–ç”Ÿå˜é‡å‘é‡ (other exogenous variables)
- $\\beta_1$ æ˜¯å¤„ç†æ•ˆåº” $X_{1i}$ çš„ç³»æ•°
- $\\boldsymbol{\\beta}$ æ˜¯å…¶ä»–å˜é‡ç³»æ•°çš„**å‘é‡** (parameter vector)

**ç¬¬ä¸€é˜¶æ®µ (First Stage):**
$$X_{1i} = \\gamma_0 + \\gamma_1 Z + \\boldsymbol{\\gamma} \\mathbf{X} + v_i$$

å…¶ä¸­ï¼š
- $Z$ æ˜¯äºŒå…ƒå·¥å…·å˜é‡ (binary instrument)
- $\\gamma_1$ æ˜¯å·¥å…·å˜é‡ $Z$ å¯¹ $X_{1i}$ çš„å½±å“ï¼ˆ**éœ€æ£€éªŒå…¶æ˜¾è‘—æ€§**)
- $\\boldsymbol{\\gamma}$ æ˜¯å…¶ä»–å¤–ç”Ÿå˜é‡ç³»æ•°çš„**å‘é‡** (parameter vector)

**ç¬¬äºŒé˜¶æ®µ (Second Stage) / 2SLSä¼°è®¡:**
$$Y_i = \\mu_0 + \\mu_1 \\hat{X}_{1i} + \\boldsymbol{\\mu} \\mathbf{X} + e_i$$

å…¶ä¸­ï¼š
- $\\hat{X}_{1i}$ æ˜¯ç¬¬ä¸€é˜¶æ®µå¯¹ $X_{1i}$ çš„**é¢„æµ‹å€¼** (fitted value from first stage)
- $\\mu_1$ æ˜¯å¤„ç†æ•ˆåº”çš„**æ— åä¼°è®¡** (unbiased estimate of treatment effect)
- $\\boldsymbol{\\mu}$ æ˜¯å…¶ä»–å˜é‡ç³»æ•°çš„**å‘é‡** (parameter vector)
    """)
    
    st.markdown("---")
    st.markdown("**æ½œåœ¨ç»“æœæ¡†æ¶ä¸­çš„å››ç±»ä¸ªä½“ä¸å¼‚è´¨æ€§å¤„ç†æ•ˆåº”** (Four Types with Heterogeneous Effects in Potential Outcomes Framework):")
    
    # åˆ›å»ºè¡¨æ ¼
    table_md = """
| ä¸ªä½“ç±»å‹ | Zâ†’D å…³ç³» | æ•°å­¦è¡¨è¾¾ | çœŸå®å¤„ç†æ•ˆåº” | è¯´æ˜ |
|---------|---------|--------|-----------|------|
| **Compliers** (ä¾ä»è€…) | å®Œå…¨éµç…§ | $D_i = Z$ | $\\beta_{1,comp} = 5.0$ | å—å·¥å…·å˜é‡å½±å“ï¼ŒZ=1æ—¶æ¥å—å¤„ç† |
| **Always-takers** | å§‹ç»ˆæ¥å— | $D_i = 1$ | $\\beta_{1,always} = 2.0$ | æ— è®ºZå¦‚ä½•éƒ½æ¥å—å¤„ç† |
| **Never-takers** | å§‹ç»ˆä¸æ¥å— | $D_i = 0$ | $\\beta_{1,never} = 2.0$ | æ— è®ºZå¦‚ä½•éƒ½ä¸æ¥å—å¤„ç† |
| **Defiers** (è¿æŠ—è€…) | è¿æŠ—æŒ‡å¯¼ | $D_i = 1 - Z$ | $\\beta_{1,defiers} = 2.0$ | è¿èƒŒå·¥å…·å˜é‡æŒ‡å¯¼çš„ä¸ªä½“ |
    """
    st.markdown(table_md)
    
    st.markdown("---")
    st.markdown("""
**LATE å®šç†åœ¨2SLSæ¡†æ¶ä¸­çš„åº”ç”¨**:

å½“æ»¡è¶³ LATE å‡è®¾æ—¶ï¼Œ2SLSç¬¬äºŒé˜¶æ®µä¼°è®¡é‡æ”¶æ•›åˆ° Compliers çš„å¹³å‡å¤„ç†æ•ˆåº”ï¼š

$$\\hat{\\mu}_1^{2SLS} \\xrightarrow{p} E[\\beta_{1,i} \\mid \\text{Complier}] = \\beta_{1,comp} = 5.0$$

**å…³é”®å‡è®¾**ï¼š
1. **æ’ä»–æ€§ (Exclusion Restriction)**: $Z$ åªé€šè¿‡ $X_{1i}$ å½±å“ $Y_i$
2. **ç›¸å…³æ€§ (Relevance)**: $\\gamma_1 \\neq 0$ï¼Œå³ $Z$ ä¸ $X_{1i}$ ç›¸å…³
3. **å•è°ƒæ€§ (Monotonicity)**: ä¸å­˜åœ¨ Defiersï¼Œå³ $P(\\text{Defier}) = 0$

å½“è¿åå•è°ƒæ€§å‡è®¾æ—¶ï¼ˆå­˜åœ¨ Defiersï¼‰ï¼Œç¬¬äºŒé˜¶æ®µçš„ $\\hat{\\mu}_1$ ä¸å†ç­‰äºä»»ä½•å•ä¸€ç¾¤ä½“çš„å¤„ç†æ•ˆåº”ã€‚
    """)
    
    # æ˜¾ç¤ºå‚æ•°è®¾ç½®
    st.markdown("---")
    st.markdown(f"#### æ¨¡å‹å‚æ•° (Model Parameters)")
    
    # åˆ›å»ºæ›´æ¸…æ™°çš„å±•ç¤º
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("**å››ç±»ä¸ªä½“æ¯”ä¾‹**")
        rows_data = []
        types = ['Compliers (ä¾ä»è€…)', 'Always-takers (å§‹ç»ˆæ¥å—)', 'Never-takers (ä»ä¸æ¥å—)', 'Defiers (è¿æŠ—è€…)']
        proportions = [prop_compliers, prop_always, prop_never, prop_defiers]
        for t, p in zip(types, proportions):
            rows_data.append({'ä¸ªä½“ç±»å‹': t, 'æ¯”ä¾‹': f'{p:.1%}'})
        
        df_types = pd.DataFrame(rows_data)
        st.dataframe(df_types, use_container_width=True)
        
        if prop_defiers > 0.01 and 'æ— Defiers' in scenario_choice:
            st.warning("âš ï¸ æ£€æµ‹åˆ° Defiersã€‚è¿™ä¼šè¿åå•è°ƒæ€§å‡è®¾ï¼")
    
    with col2:
        st.markdown("**å¼‚è´¨æ€§å¤„ç†æ•ˆåº”**")
        effect_data = []
        effects = [
            ('Compliers', beta_compliers),
            ('Always-takers', beta_always),
            ('Never-takers', beta_never),
            ('Defiers', beta_defiers)
        ]
        for t, e in effects:
            effect_data.append({'ä¸ªä½“ç±»å‹': t, '$\\\\beta_i$': f'{e:.1f}'})
        
        df_effects = pd.DataFrame(effect_data)
        st.dataframe(df_effects, use_container_width=True)

else:
    # åŸå§‹æ¨¡å‹æ˜¾ç¤º
    # Original model display
    st.markdown(f"**{text.get('original_model','åŸå§‹æ¨¡å‹ / Original model')}:**")
    st.latex(r"Y_i = \beta_0 + \beta_1 X_{1i} + \mathbf{\beta} \mathbf{X} + \varepsilon_i")
    st.markdown(f"**{text.get('first_stage','ç¬¬ä¸€é˜¶æ®µ / First stage')}:**")
    st.latex(r"X_{1i} = \pi_1 Z_i + \mathbf{\pi} \mathbf{X} + v_i")
    st.markdown(f"**{text.get('second_stage','ç¬¬äºŒé˜¶æ®µ / Second stage')}:**")
    st.latex(r"Y_i = \mu_0 + \mu_1 \widehat{X_{1i}} + \mathbf{\mu} \mathbf{X} + e_i")
    st.markdown(text.get('mu1_unbiased', r"$\\mu_1$ æ˜¯æ— åä¼°è®¡ / $\\mu_1$ is unbiased estimator"))
    st.markdown("---")
    st.markdown(f"### {text['param_detail']}")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"#### {text['variable_def']}")
        st.markdown(f"""
    - **U**: {text['error_term']}ï¼Œ$U \\sim N(0, 1)$
    - **Z**: {text['instrument']}ï¼Œ$Z \\sim N(0, 1)$
    - **X**: {text['endogenous']}
    - **Y**: {text['explained']}
        """)
    
    with col2:
        st.markdown(f"#### {text['param_meaning']}")
        st.markdown(f"""
    - **Î³ (gamma)** = {gamma:.2f}: {text['iv_strength']}
    - **Î´ (delta)** = {delta:.2f}: {text['error_transmission']}
    - **Î² (beta)** = 1.0: {text['true_effect']}
    
    {text['exclusion_condition']}
        """)

# ======================== æ•°æ®ç”Ÿæˆä¸å›å½’åˆ†æéƒ¨åˆ† (Data Generation & Regression Analysis) ========================
# è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡å¤
# Set random seed for reproducibility
np.random.seed(42)

# æ¨¡æ‹Ÿæ•°æ®
# Simulate data
n = 1000

if use_hte:
    # ======================== å¼‚è´¨æ€§å¤„ç†æ•ˆåº”æ•°æ®ç”Ÿæˆ (HTE Data Generation) ========================
    # HTEæ•°æ®ç”Ÿæˆè¿‡ç¨‹è¯´æ˜ (HTE Data Generation Process)
    # 1. ç”Ÿæˆå·¥å…·å˜é‡ Z (binary)
    # 2. æ ¹æ®é¢„è®¾æ¯”ä¾‹éšæœºåˆ†é…ä¸ªä½“ç±»å‹
    # 3. æ ¹æ®ä¸ªä½“ç±»å‹å’Œ Z å€¼ç¡®å®šå¤„ç†å˜é‡ D
    # 4. æ ¹æ®ä¸ªä½“ç±»å‹å¯¹åº”çš„ beta ç”Ÿæˆ Y
    
    # 1. ç”Ÿæˆå·¥å…·å˜é‡ Z (0 æˆ– 1)
    # 1. Generate instrument Z (binary: 0 or 1)
    Z = np.random.binomial(1, 0.5, n)
    
    # 2. éšæœºåˆ†é…ä¸ªä½“ç±»å‹
    # 2. Randomly assign individual types
    type_probs = [prop_compliers, prop_always, prop_never, prop_defiers]
    individual_types = np.random.choice(['Compliers', 'Always-takers', 'Never-takers', 'Defiers'], 
                                        size=n, p=type_probs)
    
    # 3. æ ¹æ®ç±»å‹å’Œ Z ç¡®å®šå¤„ç†å˜é‡ D
    # 3. Determine treatment variable D based on type and Z
    D = np.zeros(n)
    for i in range(n):
        if individual_types[i] == 'Compliers':
            D[i] = Z[i]  # Compliers: D = Z
        elif individual_types[i] == 'Always-takers':
            D[i] = 1  # Always-takers: D = 1
        elif individual_types[i] == 'Never-takers':
            D[i] = 0  # Never-takers: D = 0
        elif individual_types[i] == 'Defiers':
            D[i] = 1 - Z[i]  # Defiers: D = 1 - Z
    
    # 4. ç”Ÿæˆè¯¯å·®é¡¹å’Œç»“æœå˜é‡ Y
    # 4. Generate error term and outcome variable Y
    U = np.random.normal(0, 1, n)
    
    # æ ¹æ®ä¸ªä½“ç±»å‹è·å–å¯¹åº”çš„å¤„ç†æ•ˆåº”
    # Get treatment effect corresponding to individual type
    betas = np.zeros(n)
    for i in range(n):
        if individual_types[i] == 'Compliers':
            betas[i] = beta_compliers
        elif individual_types[i] == 'Always-takers':
            betas[i] = beta_always
        elif individual_types[i] == 'Never-takers':
            betas[i] = beta_never
        elif individual_types[i] == 'Defiers':
            betas[i] = beta_defiers
    
    # ç”Ÿæˆç»“æœå˜é‡ï¼šY = beta_i * D + U
    # Generate outcome variable: Y = beta_i * D + U
    Y = betas * D + U
    
    # åˆ›å»ºæ•°æ®æ¡†
    # Create dataframe
    data = pd.DataFrame({
        'Y': Y,
        'D': D,
        'Z': Z,
        'U': U,
        'type': individual_types,
        'beta': betas
    })
    
    # ç”¨äºå›å½’çš„ X åœ¨ HTE æ¨¡å‹ä¸­å®é™…ä¸Šå°±æ˜¯ D
    # For regression in HTE model, X is actually D
    X = D
else:
    # ======================== åŸå§‹ IV æ¨¡å‹æ•°æ®ç”Ÿæˆ (Original IV Model Data Generation) ========================
    # 1. ç”Ÿæˆ U (è¯¯å·®é¡¹) å’Œ Z (å·¥å…·å˜é‡)
    # 1. Generate U (error term) and Z (instrument)
    U = np.random.normal(0, 1, n)
    Z = np.random.normal(0, 1, n)
    
    # 2. X = Î³Â·Z + Î´Â·U + eâ‚
    e1 = np.random.normal(0, 1, n)
    X = gamma * Z + delta * U + e1
    
    # 3. Y = Î²â‚€ + Î²â‚Xâ‚áµ¢ + Î²Â·X + Îµ (Î² = 1.0 ä¸ºçœŸå®å€¼)
    # Y = Î²â‚€ + Î²â‚Xâ‚áµ¢ + Î²Â·X + Îµ (Î² = 1.0 is true value)
    # æ³¨ï¼šæ’ä»–æ€§æ¡ä»¶å‡è®¾Zä¸ç›´æ¥å½±å“Yï¼Œä»…é€šè¿‡Xå½±å“Y
    # Note: Exclusion restriction assumes Z affects Y only through X
    alpha = 1.0  # Î± ç³»æ•° / coefficient
    beta_true = 1.0  # Î² çœŸå®å€¼ / true value = 1.0
    e2 = np.random.normal(0, 1, n)
    Y = beta_true * X + alpha * U + e2
    
    # åˆ›å»ºæ•°æ®æ¡†
    # Create dataframe
    data = pd.DataFrame({
        'Y': Y,
        'X': X,
        'Z': Z,
        'U': U
    })

# ======================== å›å½’åˆ†æéƒ¨åˆ† (Regression Analysis) ========================

if use_hte:
    # ======================== HTE æ¨¡å‹å›å½’åˆ†æ (HTE Model Regression Analysis) ========================
    # åœ¨ HTE æ¨¡å‹ä¸­ï¼š
    # - X å®é™…ä¸Šå°±æ˜¯ D (å¤„ç†å˜é‡)
    # - Y æ˜¯æ ¹æ®äºšç¾¤ç‰¹å®šçš„å¤„ç†æ•ˆåº”ç”Ÿæˆçš„
    # In HTE model:
    # - X is actually D (treatment variable)
    # - Y is generated with subgroup-specific treatment effects
    
    # OLS å›å½’: Y = b0 + b1*D
    # OLS Regression: Y = b0 + b1*D
    D_ols = np.column_stack([np.ones(n), D])
    beta_ols = np.linalg.lstsq(D_ols, Y, rcond=None)[0]
    beta_ols_coef = beta_ols[1]
    Y_pred_ols = D_ols @ beta_ols
    
    # 2SLS å›å½’ (ä½¿ç”¨ Z ä½œä¸ºå·¥å…·å˜é‡)
    # 2SLS Regression (using Z as instrument)
    # ç¬¬ä¸€é˜¶æ®µ: D = f(Z)
    # First stage: D = f(Z)
    Z_first = np.column_stack([np.ones(n), Z])
    pi_hat = np.linalg.lstsq(Z_first, D, rcond=None)[0]
    D_pred = Z_first @ pi_hat
    
    # ç¬¬äºŒé˜¶æ®µ: Y = b0 + b1*D_pred
    # Second stage: Y = b0 + b1*D_pred
    D_second = np.column_stack([np.ones(n), D_pred])
    beta_2sls = np.linalg.lstsq(D_second, Y, rcond=None)[0]
    beta_2sls_coef = beta_2sls[1]
    Y_pred_2sls = D_second @ beta_2sls
    
    # è®¡ç®— RÂ² 
    ssr_ols = np.sum((Y - Y_pred_ols)**2)
    tss = np.sum((Y - np.mean(Y))**2)
    r2_ols = 1 - (ssr_ols / tss) if tss > 0 else 0
    
    ssr_2sls = np.sum((Y - Y_pred_2sls)**2)
    r2_2sls = 1 - (ssr_2sls / tss) if tss > 0 else 0
    
    # è®¡ç®—ç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡
    try:
        u_first = np.linalg.lstsq(Z_first, D, rcond=None)[0]
        D_pred_first = Z_first @ u_first
        ssr_first = np.sum((D - D_pred_first)**2)
        msr_z = np.sum((D_pred_first - np.mean(D))**2)
        if ssr_first / (n - 2) > 1e-10:
            f_stat = (msr_z / 1) / (ssr_first / (n - 2))
        else:
            f_stat = np.inf
    except:
        f_stat = np.nan
    
    # è®¡ç®—ä¸ªä½“ç±»å‹çš„åŠ æƒå¹³å‡å¤„ç†æ•ˆåº”
    # Calculate weighted average treatment effects for each type
    compliers_ate = beta_compliers if prop_compliers > 0 else 0
    always_ate = beta_always if prop_always > 0 else 0
    never_ate = beta_never if prop_never > 0 else 0
    defiers_ate = beta_defiers if prop_defiers > 0 else 0
    
    # LATE (Local Average Treatment Effect) ç†è®ºå€¼
    # LATE Theoretical value
    # æ ¹æ® LATE å®šç†ï¼Œ2SLS åº”è¯¥ä¼°è®¡çš„æ˜¯ Compliers çš„å¹³å‡å¤„ç†æ•ˆåº”
    # å¦‚æœæœ‰ Defiersï¼ŒLATE çš„è§£é‡Šä¼šæ”¹å˜
    # According to LATE theorem, 2SLS should estimate the average treatment effect for Compliers
    # If Defiers exist, the interpretation of LATE changes
    
    if prop_defiers == 0:
        # æ—  Defiersï¼šLATE å°±æ˜¯ Compliers çš„ ATE
        # No Defiers: LATE is exactly Compliers' ATE
        late_theoretical = compliers_ate
    else:
        # æœ‰ Defiersï¼šLATE çš„å®šä¹‰å˜å¾—å¤æ‚
        # With Defiers: LATE definition becomes complex
        # LATE = [E[Y|Z=1] - E[Y|Z=0]] / [E[D|Z=1] - E[D|Z=0]]
        # è®¡ç®—å·¥å…·å˜é‡çš„æ•ˆåº”
        # Calculate the effect of instrument
        y_given_z1 = np.mean(Y[Z == 1])
        y_given_z0 = np.mean(Y[Z == 0])
        d_given_z1 = np.mean(D[Z == 1])
        d_given_z0 = np.mean(D[Z == 0])
        
        if abs(d_given_z1 - d_given_z0) > 1e-6:
            late_theoretical = (y_given_z1 - y_given_z0) / (d_given_z1 - d_given_z0)
        else:
            late_theoretical = 0
    
    # æ˜¾ç¤ºç»“æœå¯¹æ¯”
    st.markdown("---")
    st.subheader(text['hte_results'])
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"### {text['ols_regression']}")
        st.metric("Î²Ì‚_OLS", f"{beta_ols_coef:.4f}", delta=f"{beta_ols_coef - compliers_ate:.4f}")
        st.metric("RÂ²", f"{r2_ols:.4f}")
        st.markdown(f"**{text['model']}**: Y = {beta_ols[0]:.4f} + {beta_ols_coef:.4f}Â·D")
    
    with col2:
        st.markdown(f"### {text['tsls_regression']}")
        st.metric("Î²Ì‚_2SLS (LATE)", f"{beta_2sls_coef:.4f}", delta=f"{beta_2sls_coef - late_theoretical:.4f}")
        st.metric("RÂ²", f"{r2_2sls:.4f}")
        st.markdown(f"**{text['model']}**: Y = {beta_2sls[0]:.4f} + {beta_2sls_coef:.4f}Â·D_pred")
    
    # æ˜¾ç¤ºå·¥å…·å˜é‡å¼ºåº¦
    st.markdown("---")
    st.subheader(text['iv_diagnosis'])
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(text['first_stage_f'], f"{f_stat:.2f}")
        if f_stat < 10:
            st.warning(f"âš ï¸ {text['iv_weak']}")
        else:
            st.success(f"âœ“ {text['iv_strong']}")
    
    with col2:
        correlation_dz = np.corrcoef(D, Z)[0, 1]
        st.metric(text['correlation'], f"{correlation_dz:.4f}")
    
    with col3:
        covariance_dz = np.cov(D, Z)[0, 1]
        st.metric(text['covariance'], f"{covariance_dz:.4f}")
    
    # ======================== LATE å®šç†éªŒè¯éƒ¨åˆ† (LATE Theorem Verification) ========================
    st.markdown("---")
    st.subheader(text['late_theorem'])
    
    if lang == 'zh':
        st.markdown(f"""
{text['late_explanation']}

{text['late_assumption_1']}
{text['late_assumption_2']}
{text['late_assumption_3']}

**å®éªŒåœºæ™¯åˆ†æ**ï¼š

{text['late_result_scenario1'] if prop_defiers == 0 else text['late_result_scenario2']}
        """)
    else:
        st.markdown(f"""
{text['late_explanation']}

{text['late_assumption_1']}
{text['late_assumption_2']}
{text['late_assumption_3']}

**Scenario Analysis**:

{text['late_result_scenario1'] if prop_defiers == 0 else text['late_result_scenario2']}
        """)
    
    if prop_defiers > 0:
        st.warning(f"{text['monotonicity_violation']}")
    
    # æ˜¾ç¤ºå„ç±»å‹çš„ATEå’ŒåŠ æƒæ•ˆåº”
    st.markdown("---")
    st.subheader("å¼‚è´¨æ€§å¤„ç†æ•ˆåº”å¯¹æ¯”" if lang == 'zh' else "Heterogeneous Treatment Effects Comparison")
    
    hte_comparison_data = []
    hte_comparison_data.append({
        'ä¸ªä½“ç±»å‹' if lang == 'zh' else 'Individual Type': text['compliers'],
        'æ¯”ä¾‹' if lang == 'zh' else 'Proportion': f'{prop_compliers:.0%}',
        'çœŸå®å¤„ç†æ•ˆåº”' if lang == 'zh' else 'True Effect': f'{beta_compliers:.4f}',
        'åŠ æƒè´¡çŒ®' if lang == 'zh' else 'Weighted Contribution': f'{beta_compliers * prop_compliers:.4f}'
    })
    hte_comparison_data.append({
        'ä¸ªä½“ç±»å‹' if lang == 'zh' else 'Individual Type': text['always_takers'],
        'æ¯”ä¾‹' if lang == 'zh' else 'Proportion': f'{prop_always:.0%}',
        'çœŸå®å¤„ç†æ•ˆåº”' if lang == 'zh' else 'True Effect': f'{beta_always:.4f}',
        'åŠ æƒè´¡çŒ®' if lang == 'zh' else 'Weighted Contribution': f'{beta_always * prop_always:.4f}'
    })
    hte_comparison_data.append({
        'ä¸ªä½“ç±»å‹' if lang == 'zh' else 'Individual Type': text['never_takers'],
        'æ¯”ä¾‹' if lang == 'zh' else 'Proportion': f'{prop_never:.0%}',
        'çœŸå®å¤„ç†æ•ˆåº”' if lang == 'zh' else 'True Effect': f'{beta_never:.4f}',
        'åŠ æƒè´¡çŒ®' if lang == 'zh' else 'Weighted Contribution': f'{beta_never * prop_never:.4f}'
    })
    if prop_defiers > 0:
        hte_comparison_data.append({
            'ä¸ªä½“ç±»å‹' if lang == 'zh' else 'Individual Type': text['defiers'],
            'æ¯”ä¾‹' if lang == 'zh' else 'Proportion': f'{prop_defiers:.0%}',
            'çœŸå®å¤„ç†æ•ˆåº”' if lang == 'zh' else 'True Effect': f'{beta_defiers:.4f}',
            'åŠ æƒè´¡çŒ®' if lang == 'zh' else 'Weighted Contribution': f'{beta_defiers * prop_defiers:.4f}'
        })
    
    df_hte = pd.DataFrame(hte_comparison_data)
    st.dataframe(df_hte, use_container_width=True)
    
    # è®¡ç®—ç†è®ºçš„äººå£å¹³å‡å¤„ç†æ•ˆåº” (Population ATE)
    pop_ate = (beta_compliers * prop_compliers + beta_always * prop_always + 
               beta_never * prop_never + beta_defiers * prop_defiers)
    
    if lang == 'zh':
        st.markdown(f"""
**å…³é”®ç»“æœ**:
- **äººå£å¹³å‡å¤„ç†æ•ˆåº” (Population ATE)**: {pop_ate:.4f}
- **OLS ä¼°è®¡**: {beta_ols_coef:.4f}
- **2SLS ä¼°è®¡ (LATE)**: {beta_2sls_coef:.4f}
- **ç†è®º LATE å€¼**: {late_theoretical:.4f}
- **2SLS åå·®**: {abs(beta_2sls_coef - late_theoretical):.4f}

**è§£é‡Š**:
        """)
        
        if prop_defiers == 0:
            st.success(f"""
âœ“ **åœºæ™¯ä¸€éªŒè¯æˆåŠŸ**ï¼šæ— è¿æŠ—è€…å­˜åœ¨
- 2SLS å®Œç¾æ¢å¤äº†ä¾ä»è€…çš„çœŸå®å¤„ç†æ•ˆåº” ({beta_compliers:.4f})
- IV ä¼°è®¡å€¼ ({beta_2sls_coef:.4f}) â‰ˆ ç†è®º LATE å€¼ ({late_theoretical:.4f})
- æ‰€æœ‰ LATE å‡è®¾å¾—åˆ°æ»¡è¶³ï¼ŒLATE å®šç†å®Œå…¨é€‚ç”¨
            """)
        else:
            st.error(f"""
âš ï¸ **åœºæ™¯äºŒç»“æœå±•ç¤º**ï¼šè¿æŠ—è€…çš„ç ´åæ€§å½±å“
- Defiers (å  {prop_defiers:.0%}) çš„å­˜åœ¨è¿åäº†å•è°ƒæ€§å‡è®¾
- 2SLS ä¼°è®¡å€¼ ({beta_2sls_coef:.4f}) ä¸å†å¯¹åº”ä»»ä½•å•ä¸€ç¾¤ä½“çš„å¤„ç†æ•ˆåº”
- è¿æŠ—è€…å¯¹å·¥å…·å˜é‡æ•ˆåº”çš„ä¸­æ–­å¯¼è‡´ IV ä¼°è®¡è¢«æ‰­æ›²
- è¿™è¯æ˜å•è°ƒæ€§å‡è®¾å¯¹äº LATE å®šç†çš„æœ‰æ•ˆæ€§æ˜¯å¿…è¦çš„
            """)
    else:
        st.markdown(f"""
**Key Results**:
- **Population Average Treatment Effect (ATE)**: {pop_ate:.4f}
- **OLS Estimate**: {beta_ols_coef:.4f}
- **2SLS Estimate (LATE)**: {beta_2sls_coef:.4f}
- **Theoretical LATE Value**: {late_theoretical:.4f}
- **2SLS Deviation**: {abs(beta_2sls_coef - late_theoretical):.4f}

**Explanation**:
        """)
        
        if prop_defiers == 0:
            st.success(f"""
âœ“ **Scenario I Verification Success**: No Defiers present
- 2SLS perfectly recovers Compliers' true treatment effect ({beta_compliers:.4f})
- IV estimate ({beta_2sls_coef:.4f}) â‰ˆ Theoretical LATE value ({late_theoretical:.4f})
- All LATE assumptions are satisfied, LATE theorem fully applicable
            """)
        else:
            st.error(f"""
âš ï¸ **Scenario II Results**: Destructive Impact of Defiers
- Defiers (comprising {prop_defiers:.0%}) violate the monotonicity assumption
- 2SLS estimate ({beta_2sls_coef:.4f}) no longer corresponds to any single group's effect
- Defiers' disruption of the instrument effect causes IV estimates to be distorted
- This proves monotonicity assumption is necessary for LATE theorem validity
            """)
    
    # å¯è§†åŒ–ï¼šä¸åŒå¤„ç†å€¼ä¸‹çš„Yåˆ†å¸ƒ
    st.markdown("---")
    st.subheader("æ•°æ®å¯è§†åŒ–" if lang == 'zh' else "Data Visualization")
    
    # æŒ‰å¤„ç†çŠ¶æ€å’Œç±»å‹åˆ†ç»„çš„Yå€¼åˆ†å¸ƒ
    fig_box = go.Figure()
    
    colors = {'Compliers': 'blue', 'Always-takers': 'green', 'Never-takers': 'orange', 'Defiers': 'red'}
    
    for dtype in ['Compliers', 'Always-takers', 'Never-takers', 'Defiers']:
        if dtype == 'Defiers' and prop_defiers == 0:
            continue
        mask = individual_types == dtype
        if np.any(mask):
            # D = 0 çš„æƒ…å†µ
            mask_d0 = mask & (D == 0)
            if np.any(mask_d0):
                fig_box.add_trace(go.Box(
                    y=Y[mask_d0],
                    name=f'{dtype} (D=0)',
                    marker_color=colors[dtype],
                    opacity=0.7
                ))
            
            # D = 1 çš„æƒ…å†µ
            mask_d1 = mask & (D == 1)
            if np.any(mask_d1):
                fig_box.add_trace(go.Box(
                    y=Y[mask_d1],
                    name=f'{dtype} (D=1)',
                    marker_color=colors[dtype],
                    opacity=1.0
                ))
    
    fig_box.update_layout(
        title="æŒ‰ä¸ªä½“ç±»å‹å’Œå¤„ç†çŠ¶æ€åˆ†ç»„çš„ç»“æœå˜é‡(Y)åˆ†å¸ƒ" if lang == 'zh' else "Outcome Distribution by Type and Treatment Status",
        yaxis_title="Y",
        xaxis_title="ç±»å‹å’Œå¤„ç†çŠ¶æ€" if lang == 'zh' else "Type and Treatment Status",
        boxmode='group',
        height=500
    )
    
    st.plotly_chart(fig_box, use_container_width=True)
    
else:
    # ======================== åŸå§‹ IV æ¨¡å‹å›å½’åˆ†æ (Original IV Model Regression) ========================
    # OLS å›å½’: Y = b0 + b1*X
    X_ols = np.column_stack([np.ones(n), X])
    beta_ols = np.linalg.lstsq(X_ols, Y, rcond=None)[0]
    beta_ols_coef = beta_ols[1]
    Y_pred_ols = X_ols @ beta_ols

    # 2SLS å›å½’
    # ç¬¬ä¸€é˜¶æ®µ: X = f(Z)
    X_first = np.column_stack([np.ones(n), Z])
    gamma_hat = np.linalg.lstsq(X_first, X, rcond=None)[0]
    X_pred = X_first @ gamma_hat

    # ç¬¬äºŒé˜¶æ®µ: Y = b0 + b1*X_pred
    X_second = np.column_stack([np.ones(n), X_pred])
    beta_2sls = np.linalg.lstsq(X_second, Y, rcond=None)[0]
    beta_2sls_coef = beta_2sls[1]
    Y_pred_2sls = X_second @ beta_2sls

    # è®¡ç®— RÂ² å’Œå…¶ä»–ç»Ÿè®¡é‡
    ssr_ols = np.sum((Y - Y_pred_ols)**2)
    tss = np.sum((Y - np.mean(Y))**2)
    r2_ols = 1 - (ssr_ols / tss)

    ssr_2sls = np.sum((Y - Y_pred_2sls)**2)
    r2_2sls = 1 - (ssr_2sls / tss)

    # è®¡ç®—ç¬¬ä¸€é˜¶æ®µ F ç»Ÿè®¡é‡
    try:
        Z_with_const = np.column_stack([np.ones(n), Z])
        u_first = np.linalg.lstsq(Z_with_const, X, rcond=None)[0]
        X_pred_first = Z_with_const @ u_first
        ssr_first = np.sum((X - X_pred_first)**2)
        msr_z = np.sum((X_pred_first - np.mean(X))**2)
        # é˜²æ­¢åˆ†æ¯ä¸º 0
        if ssr_first / (n - 2) > 1e-10:
            f_stat = (msr_z / 1) / (ssr_first / (n - 2))
        else:
            f_stat = np.inf
    except:
        f_stat = np.nan

    # è®¾å®šåŸå§‹æ¨¡å‹çš„çœŸå®å€¼
    beta_true = 1.0

    # æ˜¾ç¤ºç»“æœå¯¹æ¯”
    st.markdown("---")
    st.subheader(text['regression_comparison'])

    col1, col2 = st.columns(2)

    with col1:
        st.markdown(f"### {text['ols_regression']}")
        st.metric("Î²Ì‚_OLS", f"{beta_ols_coef:.4f}", delta=f"{beta_ols_coef - beta_true:.4f} ({text['true_value']}: 1.0)")
        st.metric("RÂ²", f"{r2_ols:.4f}")
        st.markdown(f"**{text['model']}**: Y = {beta_ols[0]:.4f} + {beta_ols_coef:.4f}Â·X")

    with col2:
        st.markdown(f"### {text['tsls_regression']}")
        st.metric("Î²Ì‚_2SLS", f"{beta_2sls_coef:.4f}", delta=f"{beta_2sls_coef - beta_true:.4f} ({text['true_value']}: 1.0)")
        st.metric("RÂ²", f"{r2_2sls:.4f}")
        st.markdown(f"**{text['model']}**: Y = {beta_2sls[0]:.4f} + {beta_2sls_coef:.4f}Â·X_pred")

    # æ˜¾ç¤ºå·¥å…·å˜é‡å¼ºåº¦
    st.markdown("---")
    st.subheader(text['iv_diagnosis'])
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(text['first_stage_f'], f"{f_stat:.2f}")
        if f_stat < 10:
            st.warning(f"âš ï¸ {text['iv_weak']}")
        else:
            st.success(f"âœ“ {text['iv_strong']}")

    with col2:
        correlation_xz = np.corrcoef(X, Z)[0, 1]
        st.metric(text['correlation'], f"{correlation_xz:.4f}")

    with col3:
        covariance_xz = np.cov(X, Z)[0, 1]
        st.metric(text['covariance'], f"{covariance_xz:.4f}")

    # å¯è§†åŒ–
    st.markdown("---")
    st.subheader(text['visualization'])

    # åˆ›å»º X vs Y æ•£ç‚¹å›¾ï¼Œé™„å¸¦æ‹Ÿåˆçº¿
    fig = go.Figure()

    # æ•£ç‚¹
    fig.add_trace(go.Scatter(
        x=X, y=Y,
        mode='markers',
        name=text['data_point'],
        marker=dict(color='rgba(0, 100, 200, 0.5)', size=4)
    ))

    # OLS æ‹Ÿåˆçº¿
    X_sort_idx = np.argsort(X)
    X_sort = X[X_sort_idx]
    Y_pred_ols_sort = Y_pred_ols[X_sort_idx]
    fig.add_trace(go.Scatter(
        x=X_sort, y=Y_pred_ols_sort,
        mode='lines',
        name=f'OLS (Î²Ì‚={beta_ols_coef:.4f})',
        line=dict(color='red', width=2)
    ))

    # 2SLS æ‹Ÿåˆçº¿
    Y_pred_2sls_sort = Y_pred_2sls[X_sort_idx]
    fig.add_trace(go.Scatter(
        x=X_sort, y=Y_pred_2sls_sort,
        mode='lines',
        name=f'2SLS (Î²Ì‚={beta_2sls_coef:.4f})',
        line=dict(color='green', width=2)
    ))

    fig.update_layout(
        title=text['scatter_plot'],
        xaxis_title='X',
        yaxis_title='Y',
        hovermode='closest',
        height=500
    )

    st.plotly_chart(fig, use_container_width=True)

    # æ˜¾ç¤ºå…³é”®æ´å¯Ÿ
    st.markdown("---")
    st.subheader(text['insight'])

    bias_ols = beta_ols_coef - beta_true
    bias_2sls = beta_2sls_coef - beta_true

    if lang == 'zh':
        st.markdown(f"""
- **{text['ols_bias']}**: {bias_ols:.4f} ({(bias_ols/beta_true)*100:.2f}%)
- **{text['tsls_bias']}**: {bias_2sls:.4f} ({(bias_2sls/beta_true)*100:.2f}%)
- **{text['improvement']}**: {abs(bias_ols - bias_2sls):.4f}

**{text['explanation']}**:
- å½“ Ï† > 0 æ—¶ï¼ŒZ ç›´æ¥å½±å“ Yï¼Œè¿åæ’ä»–æ€§å‡è®¾ï¼Œå¯¼è‡´ OLS æœ‰åå·®
- 2SLS é€šè¿‡å·¥å…·å˜é‡æ³•æ¶ˆé™¤è¿™ç§åå·®
- IV å¼ºåº¦ (Î³) è¶Šå¤§ï¼Œ2SLS ä¼°è®¡è¶Šç²¾ç¡®
- è¯¯å·®ä¼ å¯¼ (Î´) å½±å“ X å’Œ U çš„ç›¸å…³æ€§ï¼Œå½±å“ OLS çš„æœ‰åç¨‹åº¦
        """)
    else:
        st.markdown(f"""
- **{text['ols_bias']}**: {bias_ols:.4f} ({(bias_ols/beta_true)*100:.2f}%)
- **{text['tsls_bias']}**: {bias_2sls:.4f} ({(bias_2sls/beta_true)*100:.2f}%)
- **{text['improvement']}**: {abs(bias_ols - bias_2sls):.4f}

**{text['explanation']}**:
- When Ï† > 0, Z directly affects Y, violating exclusion restriction, causing OLS bias
- 2SLS eliminates this bias through instrumental variable method
- Larger IV strength (Î³) leads to more precise 2SLS estimates
- Error transmission (Î´) affects correlation between X and U, influencing OLS bias magnitude
        """)
